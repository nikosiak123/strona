# -*- coding: utf-8 -*-
# Wersja: OSTATECZNA (AI + Airtable + Dwuetapowa Analiza + Spersonalizowane Przypomnienia)
from flask import Flask, request, Response
import threading
import os
import json
import requests
import time
from google import genai
from google.genai import types
import errno
from config import FB_VERIFY_TOKEN, BREVO_API_KEY, FROM_EMAIL, ADMIN_EMAIL_NOTIFICATIONS
from database import DatabaseTable
import logging
from datetime import datetime, timedelta
import pytz
from apscheduler.schedulers.background import BackgroundScheduler
import atexit
import uuid

# --- Konfiguracja Og√≥lna ---
app = Flask(__name__)
VERIFY_TOKEN = os.environ.get("FB_VERIFY_TOKEN", FB_VERIFY_TOKEN)
FACEBOOK_GRAPH_API_URL = "https://graph.facebook.com/v19.0/me/messages"
HISTORY_DIR = os.path.join(os.path.dirname(__file__), "conversation_store")
MAX_HISTORY_TURNS = 10

# === ZABEZPIECZENIE PRZED SPAMEM (MESSAGE BUFFERING) ===
user_timers = {}
user_message_buffers = {}
DEBOUNCE_SECONDS = 5  # Zwiƒôkszamy do 10 sekund, ≈ºeby daƒá czas na pisanie

# --- Wczytywanie konfiguracji z pliku ---
config_path = '/home/korepetotor3/strona/config.json'
try:
    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
except (FileNotFoundError, json.JSONDecodeError) as e:
    print(f"!!! KRYTYCZNY B≈ÅƒÑD: Nie mo≈ºna wczytaƒá pliku '{config_path}': {e}")
    exit()

AI_CONFIG = config.get("AI_CONFIG", {})
AIRTABLE_CONFIG = config.get("AIRTABLE_CONFIG", {})
PAGE_CONFIG = config.get("PAGE_CONFIG", {})

PROJECT_ID = AI_CONFIG.get("PROJECT_ID")
LOCATION = AI_CONFIG.get("LOCATION")
MODEL_ID = AI_CONFIG.get("MODEL_ID")

# Inicjalizacja bazy danych SQLite (zastƒÖpienie Airtable)
try:
    clients_table = DatabaseTable('Klienci')
    print("--- Po≈ÇƒÖczenie z bazƒÖ danych SQLite OK.")
except Exception as e:
    print(f"!!! B≈ÅƒÑD: Nie mo≈ºna po≈ÇƒÖczyƒá siƒô z bazƒÖ danych: {e}")
    clients_table = None

# === NOWE STA≈ÅE DLA SYSTEMU PRZYPOMNIE≈É ===
NUDGE_TASKS_FILE = "nudge_tasks.json"
FOLLOW_UP_WINDOW_HOURS = 23
TIMEZONE = "Europe/Warsaw"
NUDGE_WINDOW_START, NUDGE_WINDOW_END = 6, 23

# --- Znaczniki i Ustawienia Modelu ---
AGREEMENT_MARKER = "[ZAPISZ_NA_LEKCJE]"
PRESENT_OFFER_MARKER = "[PREZENTUJ_OFERTE]" # <--- DODAJ Tƒò LINIƒò
EXPECTING_REPLY = "EXPECTING_REPLY"
CONVERSATION_ENDED = "CONVERSATION_ENDED"
FOLLOW_UP_LATER = "FOLLOW_UP_LATER"

GENERATION_CONFIG = types.GenerateContentConfig(
    temperature=0.7,
    top_p=0.95,
    top_k=40,
    max_output_tokens=1024,
)
SAFETY_SETTINGS = [
    types.SafetySetting(
        category=types.HarmCategory.HARM_CATEGORY_HARASSMENT,
        threshold=types.HarmBlockThreshold.BLOCK_ONLY_HIGH
    ),
    types.SafetySetting(
        category=types.HarmCategory.HARM_CATEGORY_HATE_SPEECH,
        threshold=types.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE
    ),
    types.SafetySetting(
        category=types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
        threshold=types.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE
    ),
    types.SafetySetting(
        category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
        threshold=types.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE
    ),
]

# =====================================================================
# === INICJALIZACJA GOOGLE GEN AI =====================================
# =====================================================================
gemini_client = None
try:
    GEMINI_API_KEY = config.get("AI_CONFIG", {}).get("GEMINI_API_KEY") or os.environ.get("GEMINI_API_KEY")
    
    if not GEMINI_API_KEY:
        print("!!! KRYTYCZNY B≈ÅƒÑD: Brak klucza API Gemini")
    else:
        print("--- Inicjalizowanie Google Gen AI...")
        gemini_client = genai.Client(api_key=GEMINI_API_KEY)
        print(f"--- Klient AI zainicjalizowany.")
        
        # TEST: sprawd≈∫ czy dzia≈Ça
        test_response = gemini_client.models.generate_content(
            model='gemini-1.5-flash-latest',
            contents='Hello'
        )
        print(f"--- Test po≈ÇƒÖczenia OK: {test_response.text[:30]}...")
        
except Exception as e:
    print(f"!!! KRYTYCZNY B≈ÅƒÑD inicjalizacji Gen AI: {e}", flush=True)
    gemini_client = None


# =====================================================================
# === INSTRUKCJE SYSTEMOWE DLA AI =====================================
# =====================================================================

SYSTEM_INSTRUCTION_CLASSIFIER = f"""
Twoim zadaniem jest analiza ostatniej wiadomo≈õci klienta w kontek≈õcie ca≈Çej rozmowy i sklasyfikowanie jego intencji.
Odpowiedz TYLKO I WY≈ÅƒÑCZNIE jednym z trzech status√≥w: `{EXPECTING_REPLY}`, `{CONVERSATION_ENDED}`, `{FOLLOW_UP_LATER}`.

- `{EXPECTING_REPLY}`: U≈ºyj, gdy rozmowa jest w toku, a bot oczekuje odpowiedzi na pytanie.
- `{CONVERSATION_ENDED}`: U≈ºyj, gdy klient jednoznacznie ko≈Ñczy rozmowƒô lub odrzuca ofertƒô.
- `{FOLLOW_UP_LATER}`: U≈ºyj, gdy klient deklaruje, ≈ºe odezwie siƒô p√≥≈∫niej (np. "dam znaƒá wieczorem", "muszƒô porozmawiaƒá z mƒô≈ºem").
"""

SYSTEM_INSTRUCTION_ESTIMATOR = """
Jeste≈õ ekspertem w analizie jƒôzyka naturalnego w celu estymacji czasu.
- **Aktualna data i godzina to: `__CURRENT_TIME__`.**
- **Kontekst:** Klient w≈Ça≈õnie powiedzia≈Ç, ≈ºe odezwie siƒô p√≥≈∫niej.

Na podstawie poni≈ºszej historii rozmowy, oszacuj, kiedy NAJPRAWDOPODOBNIEJ skontaktuje siƒô ponownie.
Twoja odpowied≈∫ MUSI byƒá TYLKO I WY≈ÅƒÑCZNIE datƒÖ i godzinƒÖ w formacie ISO 8601: `YYYY-MM-DDTHH:MM:SS`.

**REGU≈ÅY:**
- BƒÖd≈∫ konserwatywny, dodaj 1-2 godziny buforu do swojego oszacowania.
- Zawsze u≈ºywaj tego samego roku, co w `__CURRENT_TIME__`.
- Wynik musi byƒá w przysz≈Ço≈õci wzglƒôdem `__CURRENT_TIME__`.
- Je≈õli klient m√≥wi og√≥lnie "wieczorem", za≈Ç√≥≈º godzinƒô 20:30.
- Je≈õli klient m√≥wi "po szkole", za≈Ç√≥≈º godzinƒô 18:00.

Przyk≈Çad (zak≈ÇadajƒÖc `__CURRENT_TIME__` = `2025-09-18T15:00:00`):
- Historia: "...klient: dam znaƒá wieczorem." -> Twoja odpowied≈∫: `2025-09-18T20:30:00`
"""

SYSTEM_INSTRUCTION_GENERAL = f"""
### O Tobie (Twoja Rola)
Jeste≈õ profesjonalnym i przyjaznym asystentem klienta w centrum korepetycji online. Twoim celem jest przekonanie u≈ºytkownika do um√≥wienia pierwszej, testowej lekcji.
- **Styl Komunikacji:** Twoje wiadomo≈õci muszƒÖ byƒá KR√ìTKIE i anga≈ºujƒÖce. Zawsze ko≈Ñcz je pytaniem. Zawsze zwracaj siƒô do u≈ºytkownika per "Pa≈Ñstwo". Pamiƒôtaj, ≈ºe mo≈ºesz rozmawiaƒá zar√≥wno z rodzicem, jak i bezpo≈õrednio z uczniem. Unikaj u≈ºywania wykrzyknik√≥w. NIGDY nie powtarzaj tej samej wiadomo≈õci, je≈õli podobna znajduje siƒô ju≈º w historii.

### Informacje o Us≈Çudze
1.  **Format lekcji:**
    - Korepetycje odbywajƒÖ siƒô online, 1-na-1 z do≈õwiadczonym korepetytorem. Platforma: Microsoft Teams (wystarczy kliknƒÖƒá w link).
    - Nie oferuj korepetycji stacjonarnych.
2.  **Korepetytorzy:**
    - Korepetycji udzielajƒÖ osoby z do≈õwiadczeniem w nauczaniu online (czƒôsto studenci, ale unikaj m√≥wienia o tym wprost, chyba ≈ºe u≈ºytkownik zapyta ‚Äì wtedy potwierd≈∫, ≈ºe majƒÖ kilkuletnie do≈õwiadczenie).
    - U≈ºytkownik mo≈ºe wybraƒá konkretnego korepetytora (np. kobietƒô lub mƒô≈ºczyznƒô) podczas rezerwacji na stronie.
3.  **Logistyka:**
    - Terminy lekcji sƒÖ ustalane poprzez stronƒô rezerwacji (link wy≈õlemy p√≥≈∫niej).
    - Lekcje mo≈ºna odwo≈Çywaƒá i przek≈Çadaƒá bezp≈Çatnie w okresie podanym podczas rezerwacji.
    - **P≈Çatno≈õƒá:** Lekcjƒô testowƒÖ wyjƒÖtkowo mo≈ºna op≈Çaciƒá dopiero po po≈ÇƒÖczeniu siƒô z korepetytorem (bez ryzyka).

### Wymagane Dane
Aby system m√≥g≈Ç przygotowaƒá ofertƒô, musisz zebraƒá od klienta:
1.  **Typ szko≈Çy** (podstawowa, liceum, technikum).
2.  **Klasƒô** ucznia.
3.  **Poziom** (podstawa lub rozszerzenie) ‚Äì dotyczy TYLKO szk√≥≈Ç ≈õrednich (liceum/technikum).

**ZASADA ANALIZY HISTORII:**
ZANIM zadasz pytanie, przeanalizuj CA≈ÅƒÑ historiƒô czatu. Je≈õli u≈ºytkownik poda≈Ç ju≈º danƒÖ informacjƒô (nawet dawno temu), NIE PYTAJ PONOWNIE. Potwierd≈∫, ≈ºe wiesz i dopytaj tylko o braki.

### Prezentacja Oferty (BARDZO WA≈ªNE!)
Kiedy zdobƒôdziesz WSZYSTKIE wymagane dane (klasa, typ szko≈Çy oraz poziom je≈õli dotyczy), Twoja nastƒôpna odpowied≈∫ MUSI zawieraƒá **TYLKO I WY≈ÅƒÑCZNIE** ten tag:
`{PRESENT_OFFER_MARKER}`

**ZASADY KRYTYCZNE OFERTY:**
1. **NIGDY nie podawaj ceny samodzielnie.** Cenƒô wylicza i wysy≈Ça system zewnƒôtrzny po wykryciu tagu.
2. **NIGDY nie pisz "Mamy ofertƒô..." ani "Koszt to...".**
3. Je≈õli masz komplet danych, wy≈õlij sam tag `{PRESENT_OFFER_MARKER}`. Nie dodawaj ≈ºadnego tekstu.

### Przep≈Çyw Rozmowy
1.  **Powitanie:** Je≈õli to pierwsza wiadomo≈õƒá, przywitaj siƒô i zapytaj, czy szukajƒÖ korepetycji (chyba ≈ºe od razu napisali, ≈ºe szukajƒÖ).
2.  **Zbieranie danych:** Zapytaj o klasƒô i typ szko≈Çy.
3.  **Doprecyzowanie:** Je≈õli to szko≈Ça ≈õrednia, a nie podano poziomu ‚Äì dopytaj o poziom (podstawa/rozszerzenie).
4.  **Oferta:** Gdy masz komplet danych -> wy≈õlij tag `{PRESENT_OFFER_MARKER}`.
5.  **Zachƒôta (po ofercie):** System wy≈õle cenƒô. Wtedy Twoim zadaniem jest zachƒôcenie do lekcji testowej (przypomnij o braku ryzyka p≈Çatno≈õci).

### Obs≈Çuga Sprzeciw√≥w (Perswazja)
Nigdy nie ko≈Ñcz rozmowy po pierwszej odmowie. Pr√≥buj przekonaƒá do 3 razy.
- **Obawa: "Ucze≈Ñ bƒôdzie rozkojarzony":** Odpowiedz: "To czƒôsta obawa, ale proszƒô siƒô nie martwiƒá. Nasi korepetytorzy prowadzƒÖ lekcje w bardzo anga≈ºujƒÖcy spos√≥b."
- **Obawa: "Online siƒô nie sprawdza":** Zapytaj: "Czy ucze≈Ñ mia≈Ç ju≈º korepetycje online 1-na-1, czy do≈õwiadczenie opiera siƒô na lekcjach szkolnych z pandemii? Korepetytor korepetytorowi nier√≥wny, a nasze metody sƒÖ sprawdzone."
- **Inne (cena, niechƒôƒá):** Podkre≈õlaj zalety: elastyczne terminy, personalizowane podej≈õcie, wygoda. Zaproponuj lekcjƒô testowƒÖ bez zobowiƒÖza≈Ñ.

### Inne Zasady
- **Zakres przedmiot√≥w:** Obs≈Çugujesz WY≈ÅƒÑCZNIE matematykƒô. Je≈õli pytajƒÖ o inny przedmiot (angielski, fizyka, chemia itd.), napisz uprzejmie: "Aktualnie udzielamy korepetycji tylko z matematyki, ale chƒôtnie w niej pomo≈ºemy." i wr√≥ƒá do tematu matematyki.
- **AI / Bot:** Je≈õli zapytajƒÖ wprost, czy jeste≈õ botem, przyznaj, ≈ºe jeste≈õ automatycznym asystentem. W razie problem√≥w podaj email: edu.najechalski@gmail.com.

### Tw√≥j G≈Å√ìWNY CEL
- Kiedy rozpoznasz, ≈ºe u≈ºytkownik jednoznacznie zgadza siƒô na um√≥wienie lekcji, Twoja odpowied≈∫ dla niego MUSI byƒá kr√≥tka i MUSI ko≈Ñczyƒá siƒô specjalnym znacznikiem: `{AGREEMENT_MARKER}`.
"""

# =====================================================================
# === FUNKCJE POMOCNICZE ==============================================
# =====================================================================

def calculate_price(school, class_info, level):
    """Oblicza cenƒô. Funkcja odporna na b≈Çƒôdy odmiany i interpunkcji AI."""
    
    # LOGOWANIE DANYCH WEJ≈öCIOWYCH
    logging.info(f"[CENA_DEBUG] Start oblicze≈Ñ. Surowe dane -> Szko≈Ça: '{school}', Klasa: '{class_info}', Poziom: '{level}'")

    school_norm = str(school).lower().replace('.', '').strip()
    class_norm = str(class_info).lower().replace('.', '').replace('klasa', '').strip()
    level_norm = str(level).lower().replace('.', '').strip() if level else ""

    logging.info(f"[CENA_DEBUG] Znormalizowane -> Szko≈Ça: '{school_norm}', Klasa: '{class_norm}', Poziom: '{level_norm}'")

    if any(x in school_norm for x in ["podstawowa", "sp"]):
        logging.info("[CENA_DEBUG] Wynik: 65 z≈Ç (Wykryto szko≈Çƒô podstawowƒÖ)")
        return 65
    elif any(x in school_norm for x in ["liceum", "technikum", "lo", "tech", "≈õrednia", "zawod√≥wka"]):
        if any(x in class_norm for x in ["4", "5", "matura", "maturalna"]):
            logging.info("[CENA_DEBUG] Wynik: 80 z≈Ç (Wykryto klasƒô maturalnƒÖ)")
            return 80
        if "rozszerz" in level_norm:
            logging.info("[CENA_DEBUG] Wynik: 75 z≈Ç (Wykryto poziom rozszerzony)")
            return 75
        else:
            logging.info("[CENA_DEBUG] Wynik: 70 z≈Ç (Wykryto poziom podstawowy/domy≈õlny)")
            return 70
    
    logging.warning(f"[CENA_DEBUG] B≈ÅƒÑD: Nie dopasowano ≈ºadnej regu≈Çy cenowej dla szko≈Çy: '{school_norm}'")
    return None

def send_email_via_brevo(to_email, subject, html_content):
    """Wysy≈Ça email przez Brevo API z rozszerzonym logowaniem."""
    headers = {
        "accept": "application/json",
        "api-key": BREVO_API_KEY,
        "content-type": "application/json"
    }
    
    # Dodajemy timestamp do tematu, ≈ºeby Gmail nie ≈ÇƒÖczy≈Ç wiadomo≈õci w wƒÖtki
    unique_subject = f"{subject} [{datetime.now().strftime('%H:%M:%S')}]"

    payload = {
        "sender": {
            "name": "Bot Korepetycje",
            "email": FROM_EMAIL
        },
        "to": [{"email": to_email}],
        "subject": unique_subject,
        "htmlContent": html_content
    }
    
    try:
        logging.info(f"EMAIL_DEBUG: Pr√≥ba wys≈Çania maila do {to_email}...")
        response = requests.post("https://api.brevo.com/v3/smtp/email", json=payload, headers=headers, timeout=15)
        
        # Logujemy pe≈ÇnƒÖ odpowied≈∫ serwera
        logging.info(f"EMAIL_DEBUG: Status: {response.status_code}")
        logging.info(f"EMAIL_DEBUG: Odpowied≈∫ serwera: {response.text}")

        if response.status_code == 201:
            logging.info(f"‚úÖ Email zaakceptowany przez Brevo. ID: {response.json().get('messageId')}")
        else:
            logging.error(f"‚ùå Brevo odrzuci≈Ço maila: {response.status_code} - {response.text}")
            
    except Exception as e:
        logging.error(f"‚ùå WyjƒÖtek krytyczny w send_email_via_brevo: {e}")

def load_config():
    try:
        with open('config.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logging.critical(f"KRYTYCZNY B≈ÅƒÑD wczytywania config.json: {e}")
        return {}

def get_user_profile(psid, page_access_token):
    """Pobiera imiƒô, nazwisko i zdjƒôcie profilowe u≈ºytkownika z Facebook Graph API."""
    try:
        # Uproszczenie: Usuwamy pobieranie zdjƒôcia profilowego zgodnie z instrukcjƒÖ
        url = f"https://graph.facebook.com/v19.0/{psid}?fields=first_name,last_name&access_token={page_access_token}"
        
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        data = response.json()
        
        first_name = data.get("first_name")
        last_name = data.get("last_name")
        
        return first_name, last_name, None # Zwracamy None zamiast profile_pic_url
        
    except requests.exceptions.RequestException as e:
        logging.error(f"B≈ÇƒÖd pobierania profilu FB dla PSID {psid}: {e}")
        # Logujemy dok≈ÇadnƒÖ tre≈õƒá b≈Çƒôdu od Facebooka, ≈ºeby widzieƒá co posz≈Ço nie tak
        if hasattr(e, 'response') and e.response is not None:
             logging.error(f"Tre≈õƒá b≈Çƒôdu FB: {e.response.text}")
        return None, None, None

def create_or_find_client_in_airtable(psid, page_access_token, clients_table_obj):
    if not clients_table_obj:
        return None

    try:
        existing_client = clients_table_obj.first(formula=f"{{ClientID}} = '{psid}'")
        
        # Pr√≥ba pobrania z FB
        first_name, last_name, _ = get_user_profile(psid, page_access_token)

        if existing_client:
            return psid
        
        # Tworzenie nowego rekordu
        new_client_data = {
            "ClientID": psid,
            # Je≈õli FB zawiedzie (puste first_name), wpisz Twoje dane awaryjne
            "ImieKlienta": first_name if first_name else "Wpisz",
            "NazwiskoKlienta": last_name if last_name else "dane"
        }
            
        clients_table_obj.create(new_client_data)
        return psid
    except Exception as e:
        logging.error(f"B≈ÇƒÖd bazy danych: {e}")
        return None

def ensure_dir(directory):
    try: os.makedirs(directory)
    except OSError as e:
        if e.errno != errno.EEXIST: raise

def load_history(user_psid):
    filepath = os.path.join(HISTORY_DIR, f"{user_psid}.json")
    if not os.path.exists(filepath): return []
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            history_data = json.load(f)
        history = []
        for msg_data in history_data:
            if msg_data.get('role') in ('user', 'model') and msg_data.get('parts'):
                parts = [Part.from_text(p['text']) for p in msg_data['parts']]
                msg = genai.types.Content(role=msg_data['role'], parts=parts)
                msg.read = msg_data.get('read', False)
                msg.timestamp = msg_data.get('timestamp')
                history.append(msg)
        return history
    except Exception: return []

def save_history(user_psid, history):
    ensure_dir(HISTORY_DIR)
    filepath = os.path.join(HISTORY_DIR, f"{user_psid}.json")
    history_to_save = history  # Bez limitu d≈Çugo≈õci historii
    history_data = []
    for msg in history_to_save:
        parts_data = [{'text': part.text} for part in msg.parts]
        msg_dict = {'role': msg.role, 'parts': parts_data}
        if hasattr(msg, 'read'):
            msg_dict['read'] = msg.read
        if hasattr(msg, 'timestamp'):
            msg_dict['timestamp'] = msg.timestamp
        history_data.append(msg_dict)
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(history_data, f, indent=2)
    except Exception as e:
        logging.error(f"B≈ÅƒÑD zapisu historii dla {user_psid}: {e}")

# =====================================================================
# === FUNKCJE ZARZƒÑDZANIA PRZYPOMNIENIAMI (NUDGE) =======================
# =====================================================================
def load_nudge_tasks(tasks_file):
    if not os.path.exists(tasks_file): return {}
    try:
        with open(tasks_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception: return {}

def save_nudge_tasks(tasks, tasks_file):
    try:
        logging.info(f"Saving {len(tasks)} tasks to {tasks_file}: {[(k, v.get('status'), v.get('level')) for k, v in tasks.items()]}")
        with open(tasks_file, 'w', encoding='utf-8') as f:
            json.dump(tasks, f, indent=2)
        logging.info(f"Saved successfully")
    except Exception as e:
        logging.error(f"B≈ÇƒÖd zapisu zada≈Ñ przypomnie≈Ñ: {e}")

def cancel_nudge(psid, tasks_file):
    tasks = load_nudge_tasks(tasks_file)
    tasks_to_remove = [task_id for task_id, task in tasks.items() if task.get("psid") == psid]
    for task_id in tasks_to_remove:
        del tasks[task_id]
    if tasks_to_remove:
        save_nudge_tasks(tasks, tasks_file)
        logging.info(f"Anulowano {len(tasks_to_remove)} przypomnie≈Ñ dla PSID {psid}.")

def adjust_time_for_window(nudge_time):
    """Dostosuj czas do okna 6:00-23:00."""
    if 23 <= nudge_time.hour < 24 or 0 <= nudge_time.hour < 1:
        # Je≈õli miƒôdzy 23:00 a 1:00, wy≈õlij o 22:30 poprzedniego dnia
        nudge_time = nudge_time.replace(hour=22, minute=30, second=0, microsecond=0) - timedelta(days=1)
    elif 1 <= nudge_time.hour < 6:
        # Je≈õli miƒôdzy 1:00 a 6:00, wy≈õlij o 6:00 tego samego dnia
        nudge_time = nudge_time.replace(hour=6, minute=0, second=0, microsecond=0)
    return nudge_time

def schedule_nudge(psid, page_id, status, tasks_file, nudge_time_iso=None, nudge_message=None, level=None):
    # For expect_reply, don't cancel existing, allow multiple levels
    if status.startswith("pending_expect_reply"):
        pass
    else:
        cancel_nudge(psid, tasks_file)
    tasks = load_nudge_tasks(tasks_file)
    logging.info(f"schedule_nudge loaded {len(tasks)} tasks: {[(k, v.get('status'), v.get('level')) for k, v in tasks.items()]}")
    if status == "pending_expect_reply_2":
        for tid, t in list(tasks.items()):
            if t.get("psid") == psid and t.get("status") == "pending_expect_reply_1":
                t["status"] = "done"
                logging.info(f"Set task {tid} to done")
                break
    task_id = str(uuid.uuid4())
    task_data = {"psid": psid, "page_id": page_id, "status": status}
    if nudge_time_iso:
        nudge_time = datetime.fromisoformat(nudge_time_iso)
        nudge_time = adjust_time_for_window(nudge_time)
        task_data["nudge_time_iso"] = nudge_time.isoformat()
    if nudge_message: task_data["nudge_message"] = nudge_message
    if level: task_data["level"] = level
    tasks[task_id] = task_data
    logging.info(f"Added new task {task_id} with status {status}, level {level}, now tasks: {len(tasks)}")
    save_nudge_tasks(tasks, tasks_file)
    logging.info(f"Zaplanowano przypomnienie (status: {status}, level: {level}) dla PSID {psid} o {task_data.get('nudge_time_iso')}.")

def check_and_send_nudges():
    page_config_from_file = load_config().get("PAGE_CONFIG", {})
    if not page_config_from_file:
        logging.error("[Scheduler] B≈ÇƒÖd wczytywania konfiguracji.")
        return
    tasks = load_nudge_tasks(NUDGE_TASKS_FILE)
    #logging.info(f"[Scheduler] Za≈Çadowano {len(tasks)} zada≈Ñ przypomnie≈Ñ.")
    #logging.info(f"Tasks: {[ (k, v.get('status'), v.get('level')) for k, v in tasks.items() ]}")
    now = datetime.now(pytz.timezone(TIMEZONE))
    tasks_to_modify = {}
    for task_id, task in list(tasks.items()):
        if not task.get("status", "").startswith("pending"): continue
        try:
            nudge_time = datetime.fromisoformat(task["nudge_time_iso"])
        except (ValueError, KeyError):
            logging.error(f"[Scheduler] B≈ÇƒÖd formatu daty w zadaniu {task_id}. Usuwam zadanie.")
            task['status'] = 'failed_date_format'
            tasks_to_modify[task_id] = task
            continue
        if now >= nudge_time:
            is_in_window = NUDGE_WINDOW_START <= now.hour < NUDGE_WINDOW_END
            if is_in_window:
                logging.info(f"[Scheduler] Czas na przypomnienie (status: {task['status']}) dla PSID {task['psid']}")
                page_config = page_config_from_file.get(task["page_id"])
                if page_config and page_config.get("token"):
                    psid, token = task['psid'], page_config["token"]
                    message_to_send = task.get("nudge_message")
                    level = task.get("level", 1)
                    if message_to_send:
                        send_message_with_typing(psid, message_to_send, token)
                        logging.info(f"[Scheduler] Wys≈Çano przypomnienie poziom {level} dla PSID {psid}")
                        # Dodaj wiadomo≈õƒá przypominajƒÖcƒÖ do historii konwersacji
                        history = load_history(psid)
                        reminder_msg = Content(role="model", parts=[Part.from_text(message_to_send)])
                        history.append(reminder_msg)
                        save_history(psid, history)
                        logging.info(f"Dodano wiadomo≈õƒá przypominajƒÖcƒÖ do historii dla PSID {psid}")
                    if level == 1 and task["status"] == "pending_expect_reply_1":
                        # Schedule level 2
                        now = datetime.now(pytz.timezone(TIMEZONE))
                        nudge_time = now + timedelta(hours=6)
                        nudge_time = adjust_time_for_window(nudge_time)
                        schedule_nudge(psid, task["page_id"], "pending_expect_reply_2", NUDGE_TASKS_FILE,
                                       nudge_time_iso=nudge_time.isoformat(),
                                       nudge_message="Czy sƒÖ Pa≈Ñstwo nadal zainteresowani korepetycjami?",
                                       level=2)
                        # Reload tasks to include the newly scheduled level 2
                        tasks = load_nudge_tasks(NUDGE_TASKS_FILE)
                    task['status'] = 'done'
                    tasks_to_modify[task_id] = task
                    # Save immediately after sending to prevent duplicates
                    tasks.update(tasks_to_modify)
                    save_nudge_tasks(tasks, NUDGE_TASKS_FILE)
                    tasks_to_modify = {}
                else:
                    task["status"] = "failed_no_token"
                    tasks_to_modify[task_id] = task
            else:
                logging.info(f"[Scheduler] Z≈Ça pora. Przeplanowujƒô {task['psid']}...")
                next_day_start = now.replace(hour=NUDGE_WINDOW_START, minute=5, second=0, microsecond=0)
                if now.hour >= NUDGE_WINDOW_END: next_day_start += timedelta(days=1)
                task["nudge_time_iso"] = next_day_start.isoformat()
                tasks_to_modify[task_id] = task
    if tasks_to_modify:
        tasks.update(tasks_to_modify)
        save_nudge_tasks(tasks, NUDGE_TASKS_FILE)
        logging.info("[Scheduler] Zaktualizowano zadania przypomnie≈Ñ.")

# =====================================================================
# === NOWE FUNKCJE DLA WYSPECJALIZOWANYCH AI ==========================
# =====================================================================

def run_data_extractor_ai(history):
    """AI nr 2: WyciƒÖga ustrukturyzowane dane z ca≈Çej rozmowy."""
    logging.info("[AI_EXTRACTOR] Uruchamiam analizƒô historii rozmowy...")
    
    instruction = """
    Przeanalizuj ca≈ÇƒÖ rozmowƒô. Twoim zadaniem jest wyciƒÖgnƒÖƒá 3 kluczowe informacje: szko≈Çƒô, klasƒô i poziom.
    Odpowied≈∫ MUSI byƒá w formacie JSON.
    - `szkola`: Jedno ze s≈Ç√≥w: "Podstawowa", "Liceum", "Technikum". Je≈õli kto≈õ napisa≈Ç "zawod√≥wka", "technik" lub "LO", potraktuj to odpowiednio.
    - `klasa`: Tylko cyfra, np. 1, 2, 3, 4, 8.
    - `poziom`: Jedno ze s≈Ç√≥w: "podstawa", "rozszerzenie" lub null, je≈õli nie dotyczy lub jest to szko≈Ça podstawowa.

    Je≈õli brakuje kt√≥rej≈õ informacji, w `status` wpisz "missing_data" i w `missing` podaj listƒô brakujƒÖcych p√≥l.

    Przyk≈Çad 1 (sukces):
    { "status": "success", "szkola": "Liceum", "klasa": "4", "poziom": "podstawa" }
    Przyk≈Çad 2 (brak danych):
    { "status": "missing_data", "missing": ["klasa", "poziom"] }
    """
    
    chat_history_text = "\n".join([f"{msg.role}: {msg.parts[0].text}" for msg in history])
    full_prompt = f"{instruction}\n\nHistoria czatu:\n{chat_history_text}"
    
    try:
        response = gemini_client.models.generate_content(model='gemini-1.5-flash-latest', contents=full_prompt, generation_config=GENERATION_CONFIG, safety_settings=SAFETY_SETTINGS)
        clean_text = response.text.strip().replace("```json", "").replace("```", "").strip()
        
        # LOGOWANIE SUROWEJ ODPOWIEDZI AI
        logging.info(f"[AI_EXTRACTOR] Surowa odpowied≈∫ JSON od Gemini: {clean_text}")
        
        data = json.loads(clean_text)
        
        if data.get("status") == "success":
            logging.info(f"[AI_EXTRACTOR] SUKCES: WyciƒÖgniƒôto dane: {data}")
        else:
            logging.info(f"[AI_EXTRACTOR] BRAK DANYCH: Brakuje p√≥l: {data.get('missing')}")
            
        return data
    except (json.JSONDecodeError, AttributeError, Exception) as e:
        logging.error(f"[AI_EXTRACTOR] B≈ÅƒÑD PARSOWANIA: {e}. Odpowied≈∫ modelu: {response.text if 'response' in locals() else 'Brak'}")
        return { "status": "missing_data", "missing": ["szkola", "klasa", "poziom"] }

def run_question_creator_ai(history, missing_fields):
    """AI nr 3: Tworzy naturalne pytanie o brakujƒÖce dane."""
    instruction = f"""
    Jeste≈õ asystentem AI. Twoim zadaniem jest stworzyƒá jedno, kr√≥tkie i naturalne pytanie, aby uzupe≈Çniƒá brakujƒÖce dane.
    Brakuje nam informacji o: {', '.join(missing_fields)}.
    Na podstawie historii rozmowy, sformu≈Çuj pytanie, kt√≥re bƒôdzie logicznie pasowaƒá do konwersacji.
    """
    
    full_prompt = [Content(role="user", parts=[Part.from_text(instruction)])] + history
    
    try:
        response = gemini_client.models.generate_content(model='gemini-1.5-flash-latest', contents=full_prompt, generation_config=GENERATION_CONFIG, safety_settings=SAFETY_SETTINGS)
        return response.text.strip()
    except Exception as e:
        logging.error(f"B≈ÇƒÖd kreatora pyta≈Ñ AI: {e}")
        return "Proszƒô podaƒá wiƒôcej szczeg√≥≈Ç√≥w."

# =====================================================================
# === FUNKCJE KOMUNIKACJI Z AI ========================================
# =====================================================================
def send_message(recipient_id, message_text, page_access_token):
    if not all([recipient_id, message_text, page_access_token]): return
    params = {"access_token": page_access_token}
    payload = {"recipient": {"id": recipient_id}, "message": {"text": message_text}, "messaging_type": "RESPONSE"}
    try:
        r = requests.post(FACEBOOK_GRAPH_API_URL, params=params, json=payload, timeout=30)
        r.raise_for_status()
        logging.info(f"Wys≈Çano wiadomo≈õƒá do {recipient_id}: '{message_text[:50]}...'")
    except requests.exceptions.RequestException as e:
        logging.error(f"B≈ÇƒÖd wysy≈Çania do {recipient_id}: {e}")

def send_message_with_typing(recipient_id, message_text, page_access_token):
    if not all([recipient_id, message_text, page_access_token]): return
    params = {"access_token": page_access_token}
    
    # 1. Wy≈õlij "dymek pisania" (typing_on) - czysto wizualnie
    typing_payload = {"recipient": {"id": recipient_id}, "sender_action": "typing_on"}
    try:
        requests.post(FACEBOOK_GRAPH_API_URL, params=params, json=typing_payload, timeout=30)
    except requests.exceptions.RequestException:
        pass
    
    # 2. Wy≈õlij wiadomo≈õƒá NATYCHMIAST (bez delay i sleep)
    payload = {"recipient": {"id": recipient_id}, "message": {"text": message_text}, "messaging_type": "RESPONSE"}
    try:
        r = requests.post(FACEBOOK_GRAPH_API_URL, params=params, json=payload, timeout=30)
        r.raise_for_status()
        logging.info(f"Wys≈Çano wiadomo≈õƒá do {recipient_id}: '{message_text[:50]}...'")
    except requests.exceptions.RequestException as e:
        logging.error(f"B≈ÇƒÖd wysy≈Çania do {recipient_id}: {e}")

def classify_conversation(history):
    if not gemini_client: return EXPECTING_REPLY
    chat_history_text = "\n".join([f"Klient: {msg.parts[0].text}" if msg.role == 'user' else f"Bot: {msg.parts[0].text}" for msg in history[-4:]])
    prompt_for_analysis = f"OTO FRAGMENT HISTORII CZATU:\n---\n{chat_history_text}\n---"
    full_prompt = f"{SYSTEM_INSTRUCTION_CLASSIFIER}\n\n{prompt_for_analysis}"
    try:
        analysis_config = types.GenerateContentConfig(temperature=0.0)
        response = gemini_client.models.generate_content(
            model='gemini-1.5-flash-latest',
            contents=full_prompt,
            generation_config=analysis_config
        )
        status = response.text.strip()
        if status in [EXPECTING_REPLY, CONVERSATION_ENDED, FOLLOW_UP_LATER]: return status
        return EXPECTING_REPLY
    except Exception as e:
        logging.error(f"B≈ÅƒÑD klasyfikatora AI: {e}", exc_info=True)
        return EXPECTING_REPLY

def estimate_follow_up_time(history):
    if not gemini_client: return None
    now_str = datetime.now(pytz.timezone(TIMEZONE)).isoformat()
    formatted_instruction = SYSTEM_INSTRUCTION_ESTIMATOR.replace("__CURRENT_TIME__", now_str)
    chat_history_text = "\n".join([f"Klient: {msg.parts[0].text}" if msg.role == 'user' else f"Bot: {msg.parts[0].text}" for msg in history])
    prompt_for_analysis = f"OTO PE≈ÅNA HISTORIA CZATU:\n---\n{chat_history_text}\n---"
    full_prompt = f"{formatted_instruction}\n\n{prompt_for_analysis}"

    try:
        analysis_config = types.GenerateContentConfig(temperature=0.2)
        response = gemini_client.models.generate_content(
            model='gemini-1.5-flash-latest',
            contents=full_prompt,
            generation_config=analysis_config
        )
        time_str = response.text.strip()
        if "T" in time_str and ":" in time_str: return time_str
        return None
    except Exception as e:
        logging.error(f"B≈ÅƒÑD estymatora czasu AI: {e}", exc_info=True)
        return None

def get_gemini_response(history, prompt_details, is_follow_up=False):
    """Generuje odpowied≈∫ u≈ºywajƒÖc Google Gen AI."""
    if not gemini_client:
        return "Przepraszam, mam chwilowy problem z moim systemem."
    
    try:
        # Przygotuj prompt systemowy
        if not is_follow_up:
            system_instruction = SYSTEM_INSTRUCTION_GENERAL.format(
                prompt_details=prompt_details,
                agreement_marker=AGREEMENT_MARKER
            )
        else:
            system_instruction = ("Jeste≈õ uprzejmym asystentem. Twoim zadaniem jest napisanie kr√≥tkiej, "
                                 "spersonalizowanej wiadomo≈õci przypominajƒÖcej. Na podstawie historii rozmowy, "
                                 "nawiƒÖ≈º do ostatniego tematu i delikatnie zapytaj, czy u≈ºytkownik podjƒÖ≈Ç ju≈º decyzjƒô.")
        
        # Konwertuj historiƒô na tekst
        history_text = ""
        for msg in history[-10:]:  # ostatnie 10 wiadomo≈õci
            role = "Asystent" if msg.role == "model" else "Klient"
            if hasattr(msg, 'parts') and msg.parts:
                history_text += f"{role}: {msg.parts[0].text}\n"
        
        # Po≈ÇƒÖcz wszystko w jeden prompt
        full_prompt = f"{system_instruction}\n\nHistoria rozmowy:\n{history_text}\n\nAsystent:"
        
        # Wywo≈Çaj API
        response = gemini_client.models.generate_content(
            model='gemini-1.5-flash-latest',
            contents=full_prompt,
            generation_config=GENERATION_CONFIG,
            safety_settings=SAFETY_SETTINGS
        )
        
        generated_text = response.text.strip()
        if is_follow_up and not generated_text:
            logging.warning("AI (przypomnienie) zwr√≥ci≈Ço pusty tekst. U≈ºywam domy≈õlnej wiadomo≈õci.")
            return "Dzie≈Ñ dobry, chcia≈Çem tylko zapytaƒá, czy uda≈Ço siƒô Pa≈Ñstwu podjƒÖƒá decyzjƒô w sprawie lekcji?"
        return generated_text
        
    except Exception as e:
        logging.error(f"B≈ÅƒÑD wywo≈Çania Gen AI: {e}", exc_info=True)
        return "Przepraszam, wystƒÖpi≈Ç nieoczekiwany b≈ÇƒÖd."

# =====================================================================
# === LOGIKA OP√ì≈πNIONEGO URUCHOMIENIA (AI) ============================
# =====================================================================
def handle_conversation_logic(sender_id, recipient_id, combined_text):
    """Ta funkcja uruchamia siƒô DOPIERO po X sekundach ciszy."""
    try:
        logging.info(f"AI START: Przetwarzam zbiorczƒÖ wiadomo≈õƒá od {sender_id}: '{combined_text}'")

        # --- TUTAJ ZACZYNA SIƒò STARA LOGIKA AI ---
        
        page_config = PAGE_CONFIG.get(recipient_id)
        if not page_config: return
        page_token = page_config.get("token")
        prompt_details = page_config.get("prompt_details")
        
        history = load_history(sender_id)
        
        # Dodajemy ZBIORCZƒÑ wiadomo≈õƒá do historii
        new_msg = Content(role="user", parts=[Part.from_text(combined_text)])
        new_msg.read = False
        history.append(new_msg)

        # Sprawd≈∫ tryby specjalne
        manual_mode_active = any(msg for msg in history if msg.role == 'model' and msg.parts[0].text == 'MANUAL_MODE')
        post_reservation_mode_active = any(msg for msg in history if msg.role == 'model' and msg.parts[0].text == 'POST_RESERVATION_MODE')

        if manual_mode_active:
            logging.info(f"U≈ºytkownik {sender_id} jest w trybie rƒôcznym.")
            save_history(sender_id, history)
            return

        if post_reservation_mode_active:
            user_msg_lower = combined_text.lower()
            if "pomoc" in user_msg_lower:
                admin_email = ADMIN_EMAIL_NOTIFICATIONS
                last_msgs = "\n".join([f"Klient: {msg.parts[0].text}" if msg.role == 'user' else f"Bot: {msg.parts[0].text}" for msg in history[-5:]])
                html_content = f"<p>U≈ºytkownik {sender_id} prosi o pomoc.</p><pre>{last_msgs}</pre>"
                send_email_via_brevo(admin_email, "Pro≈õba o pomoc", html_content)
                history.append(Content(role="model", parts=[Part.from_text("MANUAL_MODE")]))
                save_history(sender_id, history)
                return
            send_message_with_typing(sender_id, 'Dziƒôkujemy za kontakt. Wpisz "POMOC" je≈õli masz pytania.', page_token)
            return

        # --- G≈Å√ìWNE WYWO≈ÅANIE AI ---
        ai_response_raw = get_gemini_response(history, prompt_details)

        if PRESENT_OFFER_MARKER in ai_response_raw:
            logging.info("Tag [PREZENTUJ_OFERTE] wykryty.")
            extracted_data = run_data_extractor_ai(history)
            if extracted_data.get("status") == "success":
                price = calculate_price(extracted_data["szkola"], extracted_data["klasa"], extracted_data.get("poziom"))
                if price:
                    final_offer = f"Oferujemy korepetycje matematyczne za {price} z≈Ç za lekcjƒô 60 minut. Czy um√≥wiƒá lekcjƒô?"
                    send_message_with_typing(sender_id, final_offer, page_token)
                    history.append(Content(role="model", parts=[Part.from_text(final_offer)]))
                else:
                    error_msg = "Nie uda≈Ço siƒô obliczyƒá ceny. Proszƒô podaƒá klasƒô i typ szko≈Çy."
                    send_message_with_typing(sender_id, error_msg, page_token)
                    history.append(Content(role="model", parts=[Part.from_text(error_msg)]))
            else:
                missing_info_message = run_question_creator_ai(history, extracted_data["missing"])
                send_message_with_typing(sender_id, missing_info_message, page_token)
                history.append(Content(role="model", parts=[Part.from_text(missing_info_message)]))

# Logika obs≈Çugi tagu [ZAPISZ_NA_LEKCJE]
        elif AGREEMENT_MARKER in ai_response_raw:
             client_id = create_or_find_client_in_airtable(sender_id, page_token, clients_table)
             if client_id:
                admin_email = ADMIN_EMAIL_NOTIFICATIONS
                subject = f"üö® NOWY KLIENT - Zgoda na lekcjƒô testowƒÖ (PSID: {sender_id})"
                email_body = f"<h3>Nowy klient wyrazi≈Ç zgodƒô na lekcjƒô!</h3><p><strong>PSID:</strong> {sender_id}</p><p>Zaktualizuj dane w panelu.</p>"
                send_email_via_brevo(admin_email, subject, email_body)
                
                reservation_link = f"https://zakrƒôcone-korepetycje.pl/rezerwacja-testowa.html?clientID={client_id}"

                # --- ZMIANA 1: Zaktualizowana tre≈õƒá wiadomo≈õci ---
                final_message_to_user = f"Utworzy≈Çem dla Pa≈Ñstwa osobisty link do rezerwacji.\n\n{reservation_link}\n\nLekcjƒô testowƒÖ mo≈ºna wyjƒÖtkowo op≈Çaciƒá po po≈ÇƒÖczeniu z korepetytorem."
                
                send_message_with_typing(sender_id, final_message_to_user, page_token)
                
                # Zapisujemy wiadomo≈õƒá bota do historii
                history.append(Content(role="model", parts=[Part.from_text(final_message_to_user)]))
                
                # --- ZMIANA 2: Dodajemy znacznik zmiany statusu rozmowy ---
                history.append(Content(role="model", parts=[Part.from_text("POST_RESERVATION_MODE")]))
                logging.info(f"U≈ºytkownik {sender_id} otrzyma≈Ç link. Przechodzƒô w tryb POST_RESERVATION_MODE.")
                # --------------------------------------------------------
                
             else:
                send_message_with_typing(sender_id, "WystƒÖpi≈Ç b≈ÇƒÖd z systemem rezerwacji.", page_token)

        else:
            # Zwyk≈Ça odpowied≈∫
            send_message_with_typing(sender_id, ai_response_raw, page_token)
            history.append(Content(role="model", parts=[Part.from_text(ai_response_raw)]))
        
        save_history(sender_id, history)

    except Exception as e:
        logging.error(f"KRYTYCZNY B≈ÅƒÑD w logice AI: {e}", exc_info=True)


# =====================================================================
# =====================================================================
# === BUFOROWANIE I ODBIERANIE WIADOMO≈öCI =============================
# =====================================================================
def process_event(event_payload):
    """Ta funkcja tylko zbiera wiadomo≈õci i zarzƒÖdza timerem."""
    try:
        sender_id = event_payload.get("sender", {}).get("id")
        recipient_id = event_payload.get("recipient", {}).get("id")
        
        # 1. Obs≈Çuga Read Receipts
        if event_payload.get("read"):
            return

        user_message_text = event_payload.get("message", {}).get("text", "").strip()
        if not user_message_text or event_payload.get("message", {}).get("is_echo"):
            return

        # Anulujemy przypomnienie NATYCHMIAST, nie czekajƒÖc 10 sekund
        cancel_nudge(sender_id, NUDGE_TASKS_FILE)

        logging.info(f"Odebrano wiadomo≈õƒá od {sender_id}: '{user_message_text}'")

        # 2. Dodaj wiadomo≈õƒá do bufora u≈ºytkownika
        if sender_id not in user_message_buffers:
            user_message_buffers[sender_id] = []
        user_message_buffers[sender_id].append(user_message_text)

        # 3. Anuluj poprzedni timer (je≈õli u≈ºytkownik znowu napisa≈Ç, przerywamy odliczanie)
        if sender_id in user_timers:
            user_timers[sender_id].cancel()

        # 4. Ustaw nowy timer (teraz na 10 sekund)
        timer = threading.Timer(DEBOUNCE_SECONDS, lambda: run_delayed_logic(sender_id, recipient_id))
        user_timers[sender_id] = timer
        timer.start()
        logging.info(f"Restart timera dla {sender_id}. Czekam {DEBOUNCE_SECONDS}s na ciszƒô...")

    except Exception as e:
        logging.error(f"B≈ÇƒÖd w process_event: {e}", exc_info=True)

def run_delayed_logic(sender_id, recipient_id):
    """Funkcja pomocnicza wywo≈Çywana przez Timer."""
    # POPRAWKA: U≈ºywamy pop(), aby pobraƒá i wyczy≈õciƒá bufor w jednym kroku
    # To zapobiega sytuacji, gdzie stara funkcja przetwarza≈Ça tekst, a nowa go nie widzia≈Ça
    messages = user_message_buffers.pop(sender_id, [])
    
    if not messages:
        return
    
    combined_text = " ".join(messages)
    
    # Usuwamy timer ze s≈Çownika, bo ju≈º siƒô wykona≈Ç
    if sender_id in user_timers:
        del user_timers[sender_id]
        
    # Uruchom w≈Ça≈õciwƒÖ logikƒô AI
    handle_conversation_logic(sender_id, recipient_id, combined_text)
        
# =====================================================================
# === WEBHOOK FLASK I URUCHOMIENIE ====================================
# =====================================================================
@app.route('/webhook', methods=['GET'])
def webhook_verification():
    if request.args.get('hub.mode') == 'subscribe' and request.args.get('hub.verify_token') == VERIFY_TOKEN:
        return Response(request.args.get('hub.challenge'), status=200)
    else:
        return Response("Verification failed", status=403)

@app.route('/webhook', methods=['POST'])
def webhook_handle():
    data = json.loads(request.data)
    if data.get("object") == "page":
        for entry in data.get("entry", []):
            for event in entry.get("messaging", []):
                thread = threading.Thread(target=process_event, args=(event,))
                thread.start()
        return Response("EVENT_RECEIVED", status=200)
    else:
        return Response("NOT_PAGE_EVENT", status=404)

if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - [%(threadName)s] - %(message)s')
    logging.getLogger('apscheduler.executors.default').setLevel(logging.WARNING)
    logging.getLogger('werkzeug').setLevel(logging.WARNING)
    logging.getLogger('apscheduler.scheduler').setLevel(logging.WARNING)
    ensure_dir(HISTORY_DIR)
    
    scheduler = BackgroundScheduler(timezone=TIMEZONE)
    scheduler.add_job(func=check_and_send_nudges, trigger="interval", seconds=30)
    scheduler.start()
    atexit.register(lambda: scheduler.shutdown())
    
    port = int(os.environ.get("PORT", 5000))
    logging.info(f"Uruchamianie serwera na porcie {port}...")
    try:
        from waitress import serve
        serve(app, host='0.0.0.0', port=port)
    except ImportError:
        app.run(host='0.0.0.0', port=port, debug=True)
